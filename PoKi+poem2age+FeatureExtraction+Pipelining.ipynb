{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o88iSofudYz8"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import FeatureUnion, Pipeline\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "from sklearn.svm import SVM\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.classifier import RandomForest"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction - Title\n"
      ],
      "metadata": {
        "id": "SQ0S60PKf5Ld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) title length by the number of tokens\n",
        "\n",
        "(2) title case (all uppercase?)\n",
        "\n",
        "(3) title article (include '^the'?)\n",
        "\n",
        "(4) title 1st person (include 'I/Me/My'?)\n",
        "\n",
        "(5) Special Symbols"
      ],
      "metadata": {
        "id": "WJigF1KTsuWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ongoing\n",
        "\n",
        "class TitlelengthTransformer(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "    return np.array([[len(title)] for title in X]).astype(int).reshape(-1, 1)\n",
        "\n",
        "class TitlecaseTransformer(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "    return np.array([[int(title.upper())] for title in X]).astype(int).reshape(-1, 1)\n",
        "\n",
        "class TitlearticleTransformer(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "    return np.array([[int('the' in title)] for title in X]).astye(int).reshape(-1, 1)\n",
        "\n",
        "class TitlefirstpersonTransformer(BaseEstimator, TransformerMixin):\n",
        "  import re\n",
        "\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "\n",
        "    I = [[re.match('^I', title) ] for title in X]\n",
        "    Me = [[re.findall('\\\\bme\\\\b', title, flags = re.I)] for title in X]\n",
        "    My = [[re.findall('\\\\bmy\\\\b', title, flags = re.I)] for title in X]\n",
        "\n",
        "    return np.array([any(x, y, z) for x in I for y in Me for z in My]).astype(int).reshape(-1, 1)\n",
        "\n",
        "\n",
        "class SpecialSymbolTransformer(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y = none):\n",
        "    return X\n",
        "\n",
        "  def transform(self, X, symbols):\n",
        "    import re\n",
        "    symbols = '|'.join(symbols)\n",
        "    pattern = re.compile(f'\\\\b{symbols}\\\\b')\n",
        "    return np.array([[bool(pattern.search(title))] for title in X])"
      ],
      "metadata": {
        "id": "L2hfCtmXdqTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SpecialSymbolTransformer Test"
      ],
      "metadata": {
        "id": "-KgKdVtNtpRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBNDj7BWtre5",
        "outputId": "2a69bb5e-c605-4715-ab1c-e0a63dfe9028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir('./drive/MyDrive/a1')\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckLDXbNVt0go",
        "outputId": "ac71cbcd-1580-4cd4-acc5-c3f6abaf5250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nlp2-a1.train',\n",
              " 'nlp2-a1.test',\n",
              " 'PoKi+A Large Dataset of Poems by Children.pdf',\n",
              " 'special_symbols.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "symbols = []\n",
        "with open('special_symbols.txt', mode = 'r', encoding = 'utf8') as f:\n",
        "  for symbol in f.readlines():\n",
        "    symbols.append(symbol.strip())"
      ],
      "metadata": {
        "id": "TzJOztHSfzRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbols"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrpLMBwhuFCp",
        "outputId": "b5454e0c-e677-4178-dde3-82a42e8badce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\\\!',\n",
              " '\\\\#',\n",
              " '\\\\$',\n",
              " '\\\\%',\n",
              " '\\\\&',\n",
              " \"\\\\'\",\n",
              " '\\\\(',\n",
              " '\\\\)',\n",
              " '\\\\*',\n",
              " '\\\\+',\n",
              " '\\\\,',\n",
              " '\\\\-',\n",
              " '\\\\.',\n",
              " '\\\\/',\n",
              " '\\\\:',\n",
              " '\\\\;',\n",
              " '\\\\<',\n",
              " '\\\\=',\n",
              " '\\\\>',\n",
              " '\\\\?',\n",
              " '\\\\@',\n",
              " '\\\\[',\n",
              " '\\\\\\\\',\n",
              " '\\\\]',\n",
              " '\\\\^',\n",
              " '\\\\`',\n",
              " '\\\\{',\n",
              " '\\\\|',\n",
              " '\\\\}',\n",
              " '\\\\~',\n",
              " '\\\\\\x81',\n",
              " '\\\\\\x8d',\n",
              " '\\\\¡',\n",
              " '\\\\¢',\n",
              " '\\\\¤',\n",
              " '\\\\¦',\n",
              " '\\\\§',\n",
              " '\\\\©',\n",
              " '\\\\\\xad',\n",
              " '\\\\¯',\n",
              " '\\\\°',\n",
              " '\\\\±',\n",
              " '\\\\´',\n",
              " '\\\\¶',\n",
              " '\\\\¸',\n",
              " '\\\\»',\n",
              " '\\\\¿',\n",
              " '\\\\˜',\n",
              " '\\\\–',\n",
              " '\\\\—',\n",
              " '\\\\‘',\n",
              " '\\\\’',\n",
              " '\\\\“',\n",
              " '\\\\”',\n",
              " '\\\\€',\n",
              " '\\\\™']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "symbols = '|'.join(symbols)"
      ],
      "metadata": {
        "id": "80GNMniwuXXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = re.compile(f'\\\\b{symbols}\\\\b')"
      ],
      "metadata": {
        "id": "_7z3t2B_uZ_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "need to escape special symbols when including them as re.compile pattern\n"
      ],
      "metadata": {
        "id": "7X0o4BBuvCnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So Class itself does not have an error, I should take care when reading the special symbol file or else escape the letters in the first time when I make special symbol file"
      ],
      "metadata": {
        "id": "lKA_L2KlvmPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have escaped special symbol letters in the first place(25.06.21. 20:26)"
      ],
      "metadata": {
        "id": "01n27STFvfmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipelining"
      ],
      "metadata": {
        "id": "LWT14B5oA5ZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "define sampler, scaler, feature extractor, estimator (some with param_grid)"
      ],
      "metadata": {
        "id": "7eTYk8Ym90Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define sampler, sacler, decomposition method, feature extractor, estimator\n",
        "sampler = SMOTETomek()\n",
        "scaler = StandardScaler()\n",
        "reduce_dim = PCA()\n",
        "feature_extractor = FeatueUnion(('#', 어쩌구), ...)\n",
        "estimator_set1 = [LogisticRegression(), SVM()]\n",
        "estimator_set2 = [RandomForest()]\n",
        "estimator_set3 = [Perceptron(), MLPClassifier()]\n",
        "\n",
        "\n",
        "# set parameter options\n",
        "Options_n_components = [2, 5, 10, 15, 20]\n",
        "Options_kernel = ['rbf', '# 어쩌구', '# 저쩌구']\n",
        "Options_C = [1, 10, 100, 1000]\n",
        "\n",
        "# set parameter grid\n",
        "param_grid = [{'reduce_dim__n_components': [2, 5, 10, 15, 20],\n",
        "               'estimator': estimator_set1,\n",
        "               'estimator__kernel' = Options_kernel,\n",
        "              'estimator__C': Options_C\n",
        "               },\n",
        "              {'reduce_dim__n_components': [2, 5, 10, 15, 20],\n",
        "               'estimator': estimator_set2,\n",
        "               'estimator__n_root': [3, 1, 2, 6],\n",
        "              'estimator__C': Options_C\n",
        "               },\n",
        "              {'reduce_dim__n_components': [2, 5, 10, 15, 20],\n",
        "               'estimator': estimator_set3,\n",
        "              'estimator__C': Options_C\n",
        "               },\n",
        "              ]"
      ],
      "metadata": {
        "id": "jEfEZJXX94pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "instantiate a pipeline"
      ],
      "metadata": {
        "id": "sdMgRZhm8mZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline([\n",
        "    ('sampler', SMOTETomek()),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('reduce_dim', reduce_dim),\n",
        "    ('estimator', 'passthrough')\n",
        "])"
      ],
      "metadata": {
        "id": "FY2L8ioV8lWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "instantiate a Cross Validation grid and fit"
      ],
      "metadata": {
        "id": "Xalm1tnW-rH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid = GridSearchCV(pipe,\n",
        "                    param_grid)\n",
        "grid.fit(#X_train, #y_train)"
      ],
      "metadata": {
        "id": "ukorTymx-npA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}